{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-criteria Algorithm for Scheduling Jobs on Cluster\n",
      "Platforms\n",
      "∗\n",
      "Pierre-Franc\n",
      "¸ois Dutot\n",
      "ID-IMAG\n",
      "51 avenue Jean Kuntzmann\n",
      "38330 Montbonnot Saint-Martin, France\n",
      "pfdutot@imag.fr\n",
      "Lionel Eyraud\n",
      "ID-IMAG\n",
      "51 avenue Jean Kuntzmann\n",
      "38330 Montbonnot Saint-Martin, France\n",
      "Lionel.Eyraud@imag.fr\n",
      "Gr´\n",
      "egory Mouni´\n",
      "e\n",
      "ID-IMAG\n",
      "51 avenue Jean Kuntzmann\n",
      "38330 Montbonnot Saint-Martin, France\n",
      "Gregory.Mounie@imag.fr\n",
      "Denis Trystram\n",
      "ID-IMAG\n",
      "51 avenue Jean Kuntzmann\n",
      "38330 Montbonnot Saint-Martin, France\n",
      "Denis.Trystram@imag.fr\n",
      "ABSTRACT\n",
      "We describe in this paper a new method for building an\n",
      "eﬃcient algorithm for scheduling jobs in a cluster. Jobs are\n",
      "considered as parallel tasks (PT) which can be scheduled on\n",
      "any number of processors. The main feature is to consider\n",
      "two criteria that are optimized together. These criteria are\n",
      "the makespan and the weighted minimal average completion\n",
      "time (minsum). They are chosen for their complementarity,\n",
      "to be able to represent both user-oriented objectives and\n",
      "system administrator objectives.\n",
      "We propose an algorithm based on a batch policy with\n",
      "increasing batch sizes, with a smart selection of jobs in each\n",
      "batch.\n",
      "This algorithm is assessed by intensive simulation\n",
      "results, compared to a new lower bound (obtained by a re-\n",
      "laxation of ILP) of the optimal schedules for both criteria\n",
      "separately. It is currently implemented in an actual real-size\n",
      "cluster platform.\n",
      "Categories and Subject Descriptors\n",
      "F.2.2 [Analysis of Algorithms and Problem Complex-\n",
      "ity]: Nonnumerical Algorithms and Problems—Sequencing\n",
      "and scheduling; D.4.1 [Operating Systems]: Process man-\n",
      "agement—Scheduling, Concurrency\n",
      "General Terms\n",
      "Algorithms, Management\n",
      "∗Authors are members of the APACHE project supported\n",
      "by CNRS, INPG, INRIA, UJF\n",
      "Permission to make digital or hard copies of all or part of this work for\n",
      "personal or classroom use is granted without fee provided that copies are\n",
      "not made or distributed for proﬁt or commercial advantage and that copies\n",
      "bear this notice and the full citation on the ﬁrst page. To copy otherwise, to\n",
      "republish, to post on servers or to redistribute to lists, requires prior speciﬁc\n",
      "permission and/or a fee.\n",
      "SPAA’04, June 27–30, 2004, Barcelona, Spain.\n",
      "Copyright 2004 ACM 1-58113-840-7/04/0006 ...$5.00.\n",
      "Keywords\n",
      "Parallel Computing, Algorithms, Scheduling, Parallel Tasks,\n",
      "Moldable Tasks, Bi-criteria\n",
      "1.\n",
      "INTRODUCTION\n",
      "1.1\n",
      "Cluster computing\n",
      "The last few years have been characterized by huge tech-\n",
      "nological changes in the area of parallel and distributed\n",
      "computing. Today, powerful machines are available at low\n",
      "price everywhere in the world. The main visible line of such\n",
      "changes is the large spreading of clusters which consist in a\n",
      "collection of tens or hundreds of standard almost identical\n",
      "processors connected together by a high speed interconnec-\n",
      "tion network [6]. The next natural step is the extension to\n",
      "local sets of clusters or to geographically distant grids [10].\n",
      "In the last issue of the Top500 ranking (from November\n",
      "2003 [1]), 52 networks of workstations (NOW) of diﬀerent\n",
      "kinds were listed and 123 entries are clusters sold either by\n",
      "IBM, HP or Dell. Looking at previous rankings we can see\n",
      "that this number (within the Top500) approximately dou-\n",
      "bled each year.\n",
      "This democratization of clusters calls for new practical\n",
      "administration tools. Even if more and more applications\n",
      "are running on such systems, there is no consensus towards\n",
      "an universal way of managing eﬃciently the computing re-\n",
      "sources. Current available scheduling algorithms were mainly\n",
      "created to provide schedules with performance guaranties for\n",
      "the makespan criterion (maximum execution time of the last\n",
      "job), however most of them are pseudo-polynomial, therefore\n",
      "the time needed to run these algorithms on real instances\n",
      "and the diﬃculty of their implementation is a drawback for\n",
      "a more popular use.\n",
      "We present in this paper a new method for scheduling\n",
      "the jobs submitted to a cluster inspired by several exist-\n",
      "ing theoretically well-founded algorithms. This method has\n",
      "been assessed on simulations and it is currently tested on\n",
      "actual conditions of use on a large cluster composed by 104\n",
      "bi-processor machines from Compaq (this cluster – called\n",
      "Icluster2 – was ranked 151 in the Top500 in June 2003).\n",
      "\n",
      "To achieve reasonable performance within reasonable time,\n",
      "we decided to build a fast algorithm which has the best fea-\n",
      "tures of existing ones. However, to speed up the algorithm\n",
      "a guaranteed performance ratio cannot be achieved, thus we\n",
      "concentrate on the average ratio on a large set of generated\n",
      "test instances.\n",
      "These instances are representative of jobs\n",
      "submitted on the Icluster [18].\n",
      "1.2\n",
      "Related approaches\n",
      "Some scheduling algorithms have been developed for clas-\n",
      "sical parallel and distributed systems of the last genera-\n",
      "tions. Clusters introduce new characteristics that are not\n",
      "really taken into account into existing scheduling modules,\n",
      "namely, unbalance between communications and computa-\n",
      "tions – communications are relatively large – or on-line sub-\n",
      "missions of jobs.\n",
      "Let us present brieﬂy some schedulers used in actual sys-\n",
      "tems: the basic idea in job schedulers [13] is to queue jobs\n",
      "and to schedule them one after the other using some simple\n",
      "rules like FCFS (First Come First Served) with priorities.\n",
      "MAUI scheduler [14] extends the model with additional fea-\n",
      "tures like fairness and backﬁlling.\n",
      "AppleS is an application level scheduler system for grid. It\n",
      "is used to schedule, for example, an application composed of\n",
      "a large set of independent jobs with shared data input ﬁles\n",
      "[4].\n",
      "It selects resources eﬃciently and takes into account\n",
      "data distribution time. It is designed for grid environment.\n",
      "There exist other parallel environments with a more gen-\n",
      "eral spectrum (heterogeneous and versatile execution plat-\n",
      "form) like Condor [16] or with special capabilities like pro-\n",
      "cessus migration, requiring system-level implementation like\n",
      "Mosix [3]. However, in these environments scheduling algo-\n",
      "rithms are online algorithms with simple rules.\n",
      "1.3\n",
      "Our approach\n",
      "As no fast and ﬂexible scheduling systems are available\n",
      "today for clusters, we started two years ago to develop a\n",
      "new system based on a sound theoretical background and\n",
      "a signiﬁcant practical experience of managing a big cluster\n",
      "(Icluster1, a 225 PC machine arrived in 2001 in our lab). It\n",
      "is based on the model of parallel tasks [9] which are inde-\n",
      "pendent jobs submitted by the users.\n",
      "We are interested here in optimizing simultaneously two\n",
      "criteria, namely the minsum (ΣCi) which is usually targeted\n",
      "by the users who all want to ﬁnish their jobs as soon as pos-\n",
      "sible, and the makespan (Cmax) which is rather a system ad-\n",
      "ministrator objective representing the total occupation time\n",
      "of the platform.\n",
      "There exist algorithms for each criterion separately; we\n",
      "propose here a bi-criteria algorithm to optimize the Cmax\n",
      "and ΣCi criteria simultaneously.\n",
      "The best existing algo-\n",
      "rithm for minimizing the makespan oﬀ-line (all jobs are\n",
      "available at the beginning) has a 3/2 + ϵ guaranty [7]. We\n",
      "can derive easily an on-line batch version by using the gen-\n",
      "eral framework of [21] leading to an approximation ratio of\n",
      "3 + ϵ. For the other criterion, the best result is 8 for the\n",
      "unweighted case and 8.53 for the weighted case [19].\n",
      "Us-\n",
      "ing a nice generic framework introduced by Hall et al.[12], a\n",
      "(12;12) approximation can be obtained at the cost of a big\n",
      "complexity which impedes the use of such algorithms.\n",
      "The paper is organized as follows: In the next section,\n",
      "we will introduce the deﬁnitions and models used in all the\n",
      "paper. The algorithm itself is described in section 3, along\n",
      "with the lower bound which is used in the experiments. The\n",
      "experimental setting and the results are discussed in section\n",
      "4. Finally we will conclude in section 5 with a discussion on\n",
      "on-going works.\n",
      "2.\n",
      "CONTEXT AND DEFINITION\n",
      "2.1\n",
      "Architectural and Computing Models\n",
      "The target execution support that we consider here is a\n",
      "cluster composed by a collection of a medium number of\n",
      "SMP or simple PC machines (typically several dozens or\n",
      "several hundreds of nodes). The nodes are fully connected\n",
      "and homogeneous.\n",
      "Primergy\n",
      "Primergy\n",
      "Primergy\n",
      "Primergy\n",
      "Primergy\n",
      "Primergy\n",
      "Primergy\n",
      "Front−end\n",
      "Job queue\n",
      "Figure 1: Job submission in clusters.\n",
      "The submissions of jobs is done by some speciﬁc nodes by\n",
      "the way of several priority queues as depicted in Figure 1.\n",
      "No other submission is allowed.\n",
      "Informally, a Parallel Task (PT) is a task that gathers\n",
      "elementary operations, typically a numerical routine or a\n",
      "nested loop, which contains itself enough parallelism to be\n",
      "executed by more than one processor. We studied scheduling\n",
      "of one speciﬁc kind of PT, denoted as moldable jobs accord-\n",
      "ing to the classiﬁcation of Feitelson et al. [8]. The number of\n",
      "processors to execute a moldable job is not ﬁxed but deter-\n",
      "mined before the execution, as opposed to rigid jobs where\n",
      "the number of processors is ﬁxed by the user at submission\n",
      "time. In any case, the number of processors does not change\n",
      "until the completion of the job.\n",
      "For historical reasons, most of submitted jobs are rigid.\n",
      "However, intrinsically, most parallel applications are mold-\n",
      "able. An application developer does not know in advance the\n",
      "exact number of processors which will be used at run time.\n",
      "Moreover, this number may vary with the input problem size\n",
      "or number of available nodes. This is also true for many nu-\n",
      "merical parallel libraries. The main exception to this rule is\n",
      "when a minimum number of processors is required because\n",
      "of time, memory or storage constraints.\n",
      "The main restriction in a systematic use of the moldable\n",
      "character is the need for a practical and reliable way to esti-\n",
      "mate (at least roughly) the parallel execution time as func-\n",
      "tion of the number of processors. Most of the time, the user\n",
      "has this knowledge but does not provide it to the scheduler,\n",
      "as it is not taken into account by rigid jobs schedulers. This\n",
      "is an inertia factor against the more systematic use of such\n",
      "models, as the users habits have to be changed.\n",
      "\n",
      "Our algorithm proposes, thanks to moldability, to eﬃ-\n",
      "ciently decrease average response time (at the users request)\n",
      "while keeping computing overhead and idle time as low as\n",
      "possible (at the system administrators request).\n",
      "2.2\n",
      "Scheduling on clusters\n",
      "The main objective function used historically is the makespan.\n",
      "This function measures the ending time of the schedule, i.e.,\n",
      "the latest completion time over all the tasks. However, this\n",
      "criterion is valid only if we consider the tasks altogether and\n",
      "from the viewpoint of a single user. If the tasks have been\n",
      "submitted by several users, other criteria can be considered.\n",
      "Let us present brieﬂy the two criteria:\n",
      "• Minimization of the makespan (Cmax = max(Cj) where\n",
      "the completion time Cj is equal to σ(j)+pj(nbproc(j))).\n",
      "pj represents the execution time of task j, σ function\n",
      "is the starting time and nbproc function is the proces-\n",
      "sor number (it can be a vector in the case of speciﬁc\n",
      "allocations for heterogeneous processors).\n",
      "• Minimization of the average completion time (ΣCi)\n",
      "[20, 2] and its variant weighted completion time (ΣωiCi).\n",
      "Such a weight may allow us to distinguish some tasks\n",
      "from each other (priority for the smallest ones, etc.).\n",
      "In a production cluster context, the jobs are submitted\n",
      "at any time. Models were the characteristics of the tasks\n",
      "(duration, release date, etc) are only known when the task\n",
      "is submitted are called on-line as opposed to the oﬀ-line\n",
      "models were all the tasks are known and available at all\n",
      "times. It is possible to schedule jobs on-line with a constant\n",
      "competitive ratio for Cmax. The idea is to schedule jobs by\n",
      "batches depending on their arrival time.\n",
      "An arriving job\n",
      "is scheduled in the next starting batch.\n",
      "This simple rule\n",
      "allows constant competitive ratio in the on-line case if a\n",
      "single batch may be scheduled with a constant competitive\n",
      "ratio ρ.\n",
      "Roughly, the last batch starts after the last task arrival\n",
      "date. By deﬁnition, all the tasks scheduled in a batch are\n",
      "scheduled in less than ρC∗\n",
      "max, where C∗\n",
      "max is the optimal oﬀ-\n",
      "line makespan of the complete instance. The length of the\n",
      "previous last batch is then lower than ρC∗\n",
      "max.\n",
      "Moreover,\n",
      "the length of the last batch, plus the starting time of the\n",
      "previous last batch (at which none of the tasks of the last\n",
      "batch were released) is less than ρ times the length of the\n",
      "optimal on-line makespan.\n",
      "As the on-line makespan is larger than the oﬀ-line makespan,\n",
      "the total schedule length is less than 2ρ times the on-line op-\n",
      "timal makespan. This is how the oﬀ-line 3/2 + ϵ algorithm\n",
      "is turned into an on-line 3 + ϵ algorithm as we said in the\n",
      "introduction.\n",
      "3.\n",
      "A NEW BICRITERIA EFFICIENT SO-\n",
      "LUTION\n",
      "3.1\n",
      "Rationale\n",
      "Studying some extreme instances and their optimal sched-\n",
      "ules for the minsum criterion, gave us an insight on the shape\n",
      "of the schedules we had to build. For example, if all the tasks\n",
      "are perfectly moldable (when the work does not depend on\n",
      "the number of processors) the optimal solution is to sched-\n",
      "ule all the tasks on all processors in order of increasing area.\n",
      "This example shows that the minsum criterion tends to give\n",
      "more importance to the smaller tasks.\n",
      "Previous algorithms presented in the literature are also de-\n",
      "signed to take into account this global structure of schedul-\n",
      "ing the smaller tasks ﬁrst. Shmoys et al. [12] used a batch\n",
      "scheduling with batches of increasing sizes. The batch length\n",
      "is doubled at each step, therefore only the smaller tasks are\n",
      "scheduled in the ﬁrst batches.\n",
      "Existing makespan algorithms for moldable tasks are also\n",
      "designed with a common structure of shelves (were all tasks\n",
      "start at the same time) which is a relaxed version of batches.\n",
      "See for example [17] or [7] for schedules with 2 shelves.\n",
      "Our algorithm was built with this structure in mind: stack-\n",
      "ing tasks in shelves of increasing sizes with the additional\n",
      "possibility of shuﬄing these shelves if necessary. However,\n",
      "our main motivation was to design a fast algorithm for the\n",
      "management of some clusters of a big regional grid in Greno-\n",
      "ble.\n",
      "Our algorithm does not have a known performance\n",
      "guaranty on the worst cases, however we tested its behavior\n",
      "on a set of generated instances which simulate real jobs sub-\n",
      "mitted on our local clusters. The principle of the algorithm\n",
      "is shown in Figure 2.\n",
      "t0\n",
      "t3\n",
      "t4\n",
      "t1 t2\n",
      "tK\n",
      "tK+1\n",
      "Figure 2: Principle of the algorithm.\n",
      "3.2\n",
      "Algorithm\n",
      "More formally, we detail below the algorithm starting with\n",
      "the input describing the instances:\n",
      "• n tasks available at time 0\n",
      "• pi(k) the processing time of task i on k processors\n",
      "• wi is its weight\n",
      "• m the number of processors\n",
      "Compute the approximate C∗\n",
      "max with the dual approx-\n",
      "imation algorithm.\n",
      "tmin = mini,j{pi(j)}\n",
      "K = ⌊log2\n",
      "\u0000C∗\n",
      "max\n",
      "tmin\n",
      "\u0001⌋\n",
      "for j = 0..K + 1 do\n",
      "tj =\n",
      "C∗\n",
      "max\n",
      "2K−j\n",
      "end for\n",
      "T = {1..n}\n",
      "for j = 0..K do\n",
      "S = {i ∈T such that ∃j, pi(j) ≤tj}\n",
      "Merge the small sequential tasks sorted by decreasing\n",
      "weight.\n",
      "Select the set Sj ⊆S of tasks to schedule in the cur-\n",
      "rent batch (using a knapsack).\n",
      "Schedule the batch between tj and tj+1.\n",
      "Remove Sj from T.\n",
      "end for\n",
      "Compact the schedule with a list algorithm using the\n",
      "batch ordering.\n",
      "\n",
      "First, our algorithm calls a dual approximation makespan\n",
      "algorithm (deﬁned in [7]) to determine an approximation\n",
      "of the optimal makespan of the instance. With this value\n",
      "C∗\n",
      "max and the smallest possible duration of a task tmin, we\n",
      "compute the smallest useful batch size t0 (such that at least\n",
      "one task can be done) and K + 1 the number of batches.\n",
      "The values tj are the length of our batches. For every j,\n",
      "tj+1 is twice the value of tj.\n",
      "The main loop of the algorithm corresponds to the selec-\n",
      "tion of the jobs to be scheduled in the current batch. We\n",
      "ﬁrst select the tasks which are not too long to run in the\n",
      "batch. If there are several tasks that can be run in less than\n",
      "half the batch size on one processor, we can merge some of\n",
      "these tasks by stacking them together. In order to have as\n",
      "much weight as possible, this merge is done by decreasing\n",
      "weight order.\n",
      "The next step is to run a knapsack selection, written with\n",
      "integer dynamic programming. We want to maximize the\n",
      "sum of the weight of the selected tasks while using at most m\n",
      "processors. The allocation of the task i is alloti, the smallest\n",
      "allocation that ﬁts (in length) into the batch.\n",
      "Values of\n",
      "W (i, j) are initialized to −∞for j < 0 and 0 otherwise. For\n",
      "i going from 1 to n and for j going from 1 to m, we compute:\n",
      "W (i, j) = max (W (i −1, j), W (i −1, j −alloti) + wi)\n",
      "The largest W (n, ·) is the maximum weight that can be done\n",
      "in the batch. The complexity of this knapsack is O(mn).\n",
      "The ﬁrst schedule is simple: we start all the selected tasks\n",
      "of one batch at the same time. A straightforward improve-\n",
      "ment is to start a task at an earlier time if all the processors\n",
      "it uses are idle. A further improvement is to use a list algo-\n",
      "rithm with the batch ordering and a local ordering within\n",
      "the batches, as it allows to change the set of processors al-\n",
      "loted to the tasks.\n",
      "Finally, an additional optimization step is used.\n",
      "The\n",
      "batch order is shuﬄed several times and the best resulting\n",
      "compact schedule is kept. This only leads to small improve-\n",
      "ments.\n",
      "The overall complexity of this algorithm is O(mnK).\n",
      "3.3\n",
      "Lower Bound\n",
      "In order to assess this algorithm with experiments, for\n",
      "each instance we need to know the value of an optimal solu-\n",
      "tion. But since the problem is NP-Hard in the strong sense,\n",
      "computing an optimal solution in reasonable time is impos-\n",
      "sible. We are thus looking for good lower bounds.\n",
      "For Cmax a good lower bound may easily be obtained by\n",
      "dual approximation [7]. For ΣCi the lower bound is com-\n",
      "puted by a relaxation of a Linear Programming formulation\n",
      "of the problem. This formulation is not intended to yield a\n",
      "feasible schedule, but rather to express constraints that are\n",
      "necessarily respected by every feasible schedule.\n",
      "For this\n",
      "formulation, we divided the time horizon into several inter-\n",
      "vals Ij = (tj, tj+1] with 0 ≤j ≤K. The values of the tj and\n",
      "the value of K are deﬁned as in the previous section.\n",
      "Once the time division is ﬁxed, we consider the decision\n",
      "variables xi,j = 1 if and only if task i ends within Ij (i.e.\n",
      "between tj and tj+1), and xi,j = 0 otherwise.\n",
      "For each task i and each interval j, we can also compute\n",
      "the minimal area occupied by task i if it ends before tj+1:\n",
      "Si,j =\n",
      "min\n",
      "1≤k≤m{kpi(k) such that pi(k) ≤tj+1}\n",
      "If the set is empty, let Si,j = +∞.\n",
      "With these values, we can give the formulation of the\n",
      "problem:\n",
      "Minimize\n",
      "\u0000 i,j witjxi,j\n",
      "Subject to\n",
      "∀i,\n",
      "\u0000 j xi,j ≥1\n",
      "∀j,\n",
      "\u0000 0≤l≤j\n",
      "\u0000 i Si,lxi,l ≤mtj+1\n",
      "∀i, ∀j,\n",
      "xi,j ∈{0, 1}\n",
      "The ﬁrst constraint expresses that every task should be\n",
      "performed at least once. The minimization criterion implies\n",
      "that no task will be performed more than once: if xi,j and\n",
      "xi,j′ are equal to one, we get a better, yet still feasible solu-\n",
      "tion by setting one of them to zero.\n",
      "The second constraint is a surface argument.\n",
      "For each\n",
      "interval Ij, we consider the tasks that end before or in this\n",
      "interval (they end in Il, for l ≤j). By deﬁnition, a task\n",
      "i ending in interval l takes up a surface at least Si,l. The\n",
      "sum of all these surfaces has to be smaller than the total\n",
      "surface between time 0 and time tj+1, which is mtj+1. This\n",
      "is obviously optimistic, because it does not take into ac-\n",
      "count collisions between tasks: scheduling according to this\n",
      "formulation might require more than m processors.\n",
      "Both of these constraints are satisﬁed by every feasible\n",
      "schedules, so for every feasible schedule S, there is a solution\n",
      "R to this linear program. Since for each job i,\n",
      "\u0000 j tjxi,j ≤\n",
      "Ci, the objective function of R is not larger than the min-\n",
      "sum criterion of the schedule S. In particular, every optimal\n",
      "schedule yields a solution to the linear program, so the op-\n",
      "timal value of the objective function is always smaller than\n",
      "the optimal value of the minsum criterion of the schedul-\n",
      "ing problem. This still holds when considering the relaxed\n",
      "problem, where xi,j is in [0; 1]. The lower bound might be\n",
      "weaker, but is much faster to compute.\n",
      "4.\n",
      "EXPERIMENTS\n",
      "4.1\n",
      "Experimental setting\n",
      "The experimental simulations presented here were per-\n",
      "formed with an ad-hoc program.\n",
      "Each experience is ob-\n",
      "tained by 40 runs; for each run tasks are generated in an\n",
      "oﬀ-line manner, then given as an input to the scheduling\n",
      "algorithm and to the linear solver which computes a lower\n",
      "bound for this instance. Comparison between the two re-\n",
      "sults yields a performance ratio, and the average ratio for\n",
      "the whole set of runs is the result of the experiments.\n",
      "The runs were made assuming a cluster of 200 processors,\n",
      "and a number of tasks varying from 25 to 400.\n",
      "In order\n",
      "to describe a mono-processor task, only its computing time\n",
      "is needed. A moldable task is described by a vector of m\n",
      "processing times (one per number of processor alloted to the\n",
      "task). We used two diﬀerent models to generate the tasks.\n",
      "The ﬁrst one generates the sequential processing times of\n",
      "the tasks, and the second one uses a parallelism model to\n",
      "derive all the other values.\n",
      "Two diﬀerent sequential workload type were used: uni-\n",
      "form and mixed cases.\n",
      "For all uniform cases, sequential\n",
      "times were generated according to an uniform distribution,\n",
      "varying from 1 to 10. For mixed cases, we introduce two\n",
      "classes :\n",
      "small and large tasks.\n",
      "The random values are\n",
      "taken with gaussian distributions centered respectively on\n",
      "1 and 10, with respective standard deviations of 0.5 and 5,\n",
      "the ratio of small tasks being 70%.\n",
      "\n",
      "Modeling the parallelism of the jobs was done in two dif-\n",
      "ferent ways. In the ﬁrst, successive processing times were\n",
      "computed with the formula pi(j) = pi(j −1) X+j\n",
      "1+j , where X\n",
      "is a random variable between 0 and 1. Depending on the\n",
      "distribution of X, tasks generated are highly parallel (with\n",
      "a quasi-linear speedup) or weakly parallel (with a speedup\n",
      "close to 1). Respectively highly and weakly parallel are gen-\n",
      "erated using gaussian distribution centered on 0.9, and 0.1,\n",
      "and with a standard deviation of 0.2. Any random value\n",
      "smaller than 0 and larger than 1 are ignored and recom-\n",
      "puted. According to the usual parallel program behavior,\n",
      "this method generates monotonic tasks, which have decreas-\n",
      "ing execution times and increasing work with k.\n",
      "For the\n",
      "mixed cases, the small tasks are weakly parallel and the\n",
      "large tasks are highly parallel.\n",
      "The second way of modeling parallelism was done accord-\n",
      "ing to a model from Cirne and Berman [5], which relies on a\n",
      "survey about the behavior of the users in a computing cen-\n",
      "ter. Only the uniform(1, 10) sequential time model is used\n",
      "for theses tasks.\n",
      "To evaluate our algorithm, we use the lower bound (cf sec-\n",
      "tion 3.3) as reference. Some simple ”standard” algorithms\n",
      "are used to compare the behavior and eﬃciency of our ap-\n",
      "proach.\n",
      "Gang : Each task is scheduled on all processors. The tasks\n",
      "are sorted using the ratio of the weight over the exe-\n",
      "cution time. This algorithm is optimal for instances\n",
      "with linear speedup.\n",
      "Sequential : Each tasks is scheduled on a single processor.\n",
      "A list algorithm is used, scheduling large processing\n",
      "time ﬁrst (LPTF).\n",
      "List Graham: All the 3 algorithms are multiprocessor list\n",
      "scheduling [11]. Every tasks is alloted using the num-\n",
      "ber of processor selected by [7]. This should lead to\n",
      "a very good average performance ratio with respect\n",
      "to the Cmax criterion.\n",
      "Only the order of the list is\n",
      "changing between the three algorithms :\n",
      "• the ﬁrst one keep the order of [7], listing ﬁrst task\n",
      "of the large shelf then the tasks of small shelf then\n",
      "the small tasks,\n",
      "• weighted largest processing time ﬁrst (LPTF), a\n",
      "classical variant, with a very god behavior for\n",
      "Cmax criterion, but the tasks are in fact sorted\n",
      "using the ratio between weighted and their exe-\n",
      "cution time.\n",
      "• smallest area ﬁrst (SAF), almost the opposite of\n",
      "LPTF, the tasks are sorted according to their area\n",
      "(number of processors × execution time).\n",
      "The\n",
      "goal is to improve the average performance ratio\n",
      "for the\n",
      "\u0000 wiCi criterion.\n",
      "In all experiments, task priority is a random value taken\n",
      "from an uniform distribution between 1 and 10.\n",
      "4.2\n",
      "Simulation results\n",
      "The results of the simulation runs are given in all the\n",
      "following ﬁgures, plotting the minimum, maximum and av-\n",
      "erage values for Cmax and\n",
      "\u0000 wiCi. The average of the com-\n",
      "petitive ratio is computed by dividing the sum of the execu-\n",
      "tion times over the sum of the lower bounds for every point\n",
      "[15]. Every workload type are represented separately. The\n",
      "same scale is represented for identical criterion between the\n",
      "workload type.\n",
      "The tasks of Figure 3 are weakly parallel.\n",
      "This is the\n",
      "worst case for our algorithm as it spends resources to accel-\n",
      "erate completion of small and high priority parallel tasks.\n",
      "These resources are thus spend without much gain. Note\n",
      "that Gang scheduling does not appear in the presented range\n",
      "for Cmax, as Gang always has a very big ratio in this case.\n",
      "As expected, the average performance ratio for our algo-\n",
      "rithm is worse than all other algorithms except Gang. Nev-\n",
      "ertheless, the performance ratio for Cmax is no more than\n",
      "2. All other algorithms have an average performance ratio\n",
      "around 1.5. The diﬀerence is large enough to inﬂuence also\n",
      "the results for the minsum criterion. From this case we may\n",
      "deduce that for most cases, our algorithms will not be much\n",
      "worse than a performance ratio of 2 for both criterion.\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 8\n",
      " 0\n",
      " 50\n",
      " 100\n",
      " 150\n",
      " 200\n",
      " 250\n",
      " 300\n",
      " 350\n",
      " 400\n",
      " 450\n",
      "WiCi ratio\n",
      "Number of tasks\n",
      "Weakly Parallel\n",
      "DEMT\n",
      "Gang\n",
      "Sequential\n",
      "List Scheduling\n",
      "SAF\n",
      "LPTF\n",
      " 1\n",
      " 1.5\n",
      " 2\n",
      " 2.5\n",
      " 3\n",
      " 3.5\n",
      " 0\n",
      " 50\n",
      " 100\n",
      " 150\n",
      " 200\n",
      " 250\n",
      " 300\n",
      " 350\n",
      " 400\n",
      " 450\n",
      "Cmax ratio\n",
      "Number of tasks\n",
      "Weakly Parallel\n",
      "DEMT\n",
      "Gang\n",
      "Sequential\n",
      "List Scheduling\n",
      "SAF\n",
      "LPTF\n",
      "Figure 3: Performance ratio for the simulation on\n",
      "200 processors, weakly parallel tasks\n",
      "Figure 4 presents the same experiments with the highly\n",
      "parallel tasks. On the minsum criterion, our algorithm is\n",
      "clearly the best one.\n",
      "Gang and sequential have opposite\n",
      "behavior on both criteria, Gang being good with a small\n",
      "number of tasks and sequential good for a large number of\n",
      "tasks only. The other algorithms are stable (with respect to\n",
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 8\n",
      " 0\n",
      " 50\n",
      " 100\n",
      " 150\n",
      " 200\n",
      " 250\n",
      " 300\n",
      " 350\n",
      " 400\n",
      " 450\n",
      "WiCi ratio\n",
      "Number of tasks\n",
      "Higly Parallel\n",
      "DEMT\n",
      "Gang\n",
      "Sequential\n",
      "List Scheduling\n",
      "SAF\n",
      "LPTF\n",
      " 1\n",
      " 1.5\n",
      " 2\n",
      " 2.5\n",
      " 3\n",
      " 3.5\n",
      " 0\n",
      " 50\n",
      " 100\n",
      " 150\n",
      " 200\n",
      " 250\n",
      " 300\n",
      " 350\n",
      " 400\n",
      " 450\n",
      "Cmax ratio\n",
      "Number of tasks\n",
      "Higly Parallel\n",
      "DEMT\n",
      "Gang\n",
      "Sequential\n",
      "List Scheduling\n",
      "SAF\n",
      "LPTF\n",
      "Figure 4: Performance ratio for the simulation on\n",
      "200 processors, highly parallel tasks\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 8\n",
      " 0\n",
      " 50\n",
      " 100\n",
      " 150\n",
      " 200\n",
      " 250\n",
      " 300\n",
      " 350\n",
      " 400\n",
      " 450\n",
      "WiCi ratio\n",
      "Number of tasks\n",
      "Mixed\n",
      "DEMT\n",
      "Gang\n",
      "Sequential\n",
      "List Scheduling\n",
      "SAF\n",
      "LPTF\n",
      " 1\n",
      " 1.5\n",
      " 2\n",
      " 2.5\n",
      " 3\n",
      " 3.5\n",
      " 0\n",
      " 50\n",
      " 100\n",
      " 150\n",
      " 200\n",
      " 250\n",
      " 300\n",
      " 350\n",
      " 400\n",
      " 450\n",
      "Cmax ratio\n",
      "Number of tasks\n",
      "Mixed\n",
      "DEMT\n",
      "Gang\n",
      "Sequential\n",
      "List Scheduling\n",
      "SAF\n",
      "LPTF\n",
      "Figure 5: Performance ratio for the simulation on\n",
      "200 processors, mixed model parallel tasks\n",
      "\n",
      "the number of tasks) but with a larger ratio on the minsum.\n",
      "Remark that the allotment computed for list algorithms is\n",
      "quite good, as Cmax performance ratio of these algorithms\n",
      "is always smaller than 2.\n",
      "The next experiment (cf Figure 5) presents mixed in-\n",
      "stances with some large tasks and plenty of small tasks. In\n",
      "this cases our algorithm is still quite stable with a perfor-\n",
      "mance ratio of around 2 for both criterion, however SAF is\n",
      "better than our algorithm. The ratio of the two other list\n",
      "algorithms greatly increase with the number of tasks, which\n",
      "points out that the order of tasks is very important here.\n",
      "Finally, the last experiment use a well known workload\n",
      "generator which emulates real applications [5]. In this more\n",
      "realistic setting our algorithm clearly outperforms the other\n",
      "ones for the minsum criterion, and is also the only one to\n",
      "keep a stable ratio for any number of tasks.\n",
      "Several observations can be made from these results. First,\n",
      "the performance ratio for the minsum criterion is never more\n",
      "than 2.5, and is on average around 2. The performance ratio\n",
      "for the makespan is almost always below 2, and is 1.9 on av-\n",
      "erage. This is very good, even for each criterion separately.\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 8\n",
      " 0\n",
      " 50\n",
      " 100\n",
      " 150\n",
      " 200\n",
      " 250\n",
      " 300\n",
      " 350\n",
      " 400\n",
      " 450\n",
      "WiCi ratio\n",
      "Number of tasks\n",
      "Cirne\n",
      "DEMT\n",
      "Gang\n",
      "Sequential\n",
      "List Scheduling\n",
      "SAF\n",
      "LPTF\n",
      " 1\n",
      " 1.5\n",
      " 2\n",
      " 2.5\n",
      " 3\n",
      " 3.5\n",
      " 0\n",
      " 50\n",
      " 100\n",
      " 150\n",
      " 200\n",
      " 250\n",
      " 300\n",
      " 350\n",
      " 400\n",
      " 450\n",
      "Cmax ratio\n",
      "Number of tasks\n",
      "Cirne\n",
      "DEMT\n",
      "Gang\n",
      "Sequential\n",
      "List Scheduling\n",
      "SAF\n",
      "LPTF\n",
      "Figure 6: Performance ratio for the simulation on\n",
      "200 processors, cirne model parallel tasks\n",
      "The second observation is that our algorithm performs\n",
      "better when tasks are more parallel. This can be understood\n",
      "if we remark that, for a weakly parallel task, there is only\n",
      "one or two intervals in which it can be scheduled without\n",
      "degrading its performance. So the scheduling algorithm is\n",
      "more constrained when the tasks are not parallel.\n",
      "The SAF algorithm perform quite well on simple cases. It\n",
      "appears on complex cases that our approach is required to\n",
      "keep a good performance on the minsum criterion. Thus our\n",
      "algorithms should be preferred in actual applications as its\n",
      "performance ratio for minsum is insensitive to jobs behavior\n",
      "and its performance ratio for the makespan is not far from\n",
      "alternatives.\n",
      "Finally, Figure 7 shows that the execution time of our\n",
      "scheduling algorithm is low (less than 2 seconds for the\n",
      "largest instances), as expected.\n",
      " 0\n",
      " 0.2\n",
      " 0.4\n",
      " 0.6\n",
      " 0.8\n",
      " 1\n",
      " 1.2\n",
      " 1.4\n",
      " 1.6\n",
      " 1.8\n",
      " 0\n",
      " 50\n",
      " 100\n",
      " 150\n",
      " 200\n",
      " 250\n",
      " 300\n",
      " 350\n",
      " 400\n",
      " 450\n",
      "Time (s)\n",
      "Number of tasks\n",
      "Weakly Parallel\n",
      "Cirne\n",
      "Highly Parallel\n",
      "Figure 7: Execution time of the algorithm.\n",
      "5.\n",
      "CONCLUDING REMARKS\n",
      "In this paper we presented a new algorithm for scheduling\n",
      "a set of independent jobs on a cluster. The main feature\n",
      "is to optimize two criteria simultaneously. The experiments\n",
      "show that in average the performance ratio is very good, and\n",
      "the algorithm is fast enough for practical use. The algorithm\n",
      "has been assessed by comparing the minsum performance to\n",
      "a new lower bound based on the relaxation of an ILP, and\n",
      "comparing the makespan performance to the best known\n",
      "approximation. Actual results are not available at the mo-\n",
      "ment, but we are currently implementing this algorithm on\n",
      "a full-scale platform (Icluster2).\n",
      "Several technical problems still have to be solved for an\n",
      "even more eﬃcient practical solution, namely the reserva-\n",
      "tion of nodes which reduces the size of the cluster and the\n",
      "mix of diﬀerent types of jobs (moldable jobs, rigid jobs, and\n",
      "divisible load jobs).\n",
      "6.\n",
      "REFERENCES\n",
      "[1] The top500 organization website.\n",
      "http://www.top500.org.\n",
      "[2] F. Afrati, E. Bampis, A. V. Fishkin, K. Jansen, and\n",
      "C. Kenyon. Scheduling to minimize the average\n",
      "completion time of dedicated tasks. Lecture Notes in\n",
      "Computer Science, vol. 1974, 2000.\n",
      "\n",
      "[3] A. Barak and O. La’adan. The MOSIX multicomputer\n",
      "operating system for high performance cluster\n",
      "computing. Future Generation Computer Systems,\n",
      "13(4–5):361–372, Mar. 1998.\n",
      "[4] H. Casanova, G. Obertelli, F. Berman, and R. Wolski.\n",
      "The AppLeS parameter sweep template: User-level\n",
      "middleware for the grid. In Proceedings of\n",
      "SuperComputing’2000, Nov 2000.\n",
      "[5] W. Cirne and F. Berman. A model for moldable\n",
      "supercomputer jobs. In 15th Intl. Parallel &\n",
      "Distributed Processing Symp., 2001.\n",
      "[6] D. E. Culler, J. P. Singh, and A. Gupta. Parallel\n",
      "Computer Architecture: A Hardware/Software\n",
      "Approach. Morgan Kaufmann Publishers, inc., San\n",
      "Francisco, CA, 1999.\n",
      "[7] P.-F. Dutot, G. Mouni´\n",
      "e, and D. Trystram. Handbook\n",
      "of Scheduling, chapter Scheduling Parallel Tasks -\n",
      "Approximation Algorithms. CRC Press, 2004. chapter\n",
      "28 of this book.\n",
      "[8] D. G. Feitelson. Scheduling parallel jobs on clusters.\n",
      "In R. Buyya, editor, High Performance Cluster\n",
      "Computing, volume 1, Architectures and Systems,\n",
      "pages 519–533. Prentice Hall PTR, Upper Saddle\n",
      "River, NJ, 1999. Chap. 21.\n",
      "[9] D. G. Feitelson and L. Rudolph. Parallel job\n",
      "scheduling: Issues and approaches. Lecture Notes in\n",
      "Computer Science, 0(949):1–18, 1995.\n",
      "[10] I. Foster and C. Kesselman. The grid: blueprint for a\n",
      "new computing infrastructure. Morgan Kaufmann\n",
      "Publishers Inc., 1999.\n",
      "[11] M. R. Garey and R. L. Graham. Bounds on\n",
      "multiprocessor scheduling with resource constraints.\n",
      "SIAM Journal on Computing, 4:187–200, 1975.\n",
      "[12] L. A. Hall, A. S. Schulz, D. B. Shmoys, and J. Wein.\n",
      "Scheduling to minimize average completion time:\n",
      "Oﬀ-line and on-line approximation algorithms.\n",
      "Mathematics of Operations Research, 22:513–544,\n",
      "1997.\n",
      "[13] R. L. Henderson. Job scheduling under the portable\n",
      "batch system. In D. G. Feitelson and L. Rudolph,\n",
      "editors, Job Scheduling Strategies for Parallel\n",
      "Processing, volume 949 of LNCS, pages 279–294, 1995.\n",
      "[14] D. Jackson, Q. Snell, and M. J. Clement. Core\n",
      "algorithms of the maui schedule. In D. G. Feitelson\n",
      "and L. Rudolph, editors, Job Scheduling Strategies for\n",
      "Parallel Processing, volume 2221 of LNCS, pages\n",
      "87–102, 2001.\n",
      "[15] R. Jain. The art of computer systems performance\n",
      "analysis. John Wiley, New York, 1991.\n",
      "[16] M. J. Litzkow, M. Livny, and M. W. Mutka. Condor :\n",
      "A hunter of idle workstations. In 8th International\n",
      "Conference on Distributed Computing Systems\n",
      "(ICDCS ’88), pages 104–111, Washington, D.C., USA,\n",
      "June 1988. IEEE Computer Society Press.\n",
      "[17] G. Mouni´\n",
      "e, C. Rapine, and D. Trystram. Eﬃcient\n",
      "approximation algorithms for scheduling malleable\n",
      "tasks. In Eleventh ACM Symposium on Parallel\n",
      "Algorithms and Architectures (SPAA’99), pages 23–32.\n",
      "ACM, juin 1999.\n",
      "[18] E. Romagnoli, Y. Denneulin, and D. Trystram. A\n",
      "synthetic workload generator for cluster computing. In\n",
      "3rd International Workshop on Performance\n",
      "Modeling, Evaluation, and Optimization of Parallel\n",
      "and Distributed Systems (PMEO-PDS’2004) in\n",
      "conjunction with IPDPS’04, Santa Fe, New Mexico,\n",
      "2004.\n",
      "[19] U. Schwiegelshohn, W. Ludwig, J. Wolf, J. Turek, and\n",
      "P. Yu. Smart SMART bounds for weighted response\n",
      "time scheduling. SIAM Journal on Computing, 28,\n",
      "1998.\n",
      "[20] H. Shachnai and J. Turek. Multiresource malleable\n",
      "task scheduling to minimize response time.\n",
      "Information Processing Letters, 70:47–52, 1999.\n",
      "[21] D. Shmoys, J. Wein, and D. Williamson. Scheduling\n",
      "parallel machine on-line. SIAM Journal on\n",
      "Computing, 24(6):1313–1331, 1995.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = pymupdf.open(\"../data/pdfs/sample.pdf\")\n",
    "\n",
    "for page in doc:\n",
    "    text = page.get_text()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
